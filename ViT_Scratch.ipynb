{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PtPBltpFOCp",
        "outputId": "dec29a6f-406d-477d-9e2c-141f56e3306b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: patchify in /usr/local/lib/python3.8/dist-packages (0.2.3)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.8/dist-packages (from patchify) (1.21.6)\n"
          ]
        }
      ],
      "source": [
        "!pip install patchify"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tx5LZaFbEaV7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
        "import numpy as np\n",
        "import cv2\n",
        "from glob import glob\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from patchify import patchify"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "13p3K45PElgs"
      },
      "outputs": [],
      "source": [
        "\"\"\" Hyperparameters \"\"\"\n",
        "hp = {}\n",
        "hp['image_size'] = 200\n",
        "hp['num_channels'] = 3\n",
        "hp['patch_size'] = 25\n",
        "hp['num_patches'] = (hp['image_size']**2) // (hp['patch_size']**2)\n",
        "hp['flat_patches_shape'] = (hp['num_patches'],hp['patch_size']*hp['patch_size']*hp['num_channels'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UYoacMcMEll5"
      },
      "outputs": [],
      "source": [
        "hp[\"batch_size\"] = 32\n",
        "hp[\"lr\"] = 1e-4\n",
        "hp[\"num_epochs\"] = 500\n",
        "hp[\"num_classes\"] = 6\n",
        "hp[\"class_names\"] = ['SCC','BCC','MEL','NEV','ACK','SEK']\n",
        "\n",
        "hp[\"num_layers\"] = 12\n",
        "hp[\"hidden_dim\"] = 768\n",
        "hp[\"mlp_dim\"] = 3072\n",
        "hp[\"num_heads\"] = 12\n",
        "hp[\"dropout_rate\"] = 0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ULc6k3GDIBzC"
      },
      "outputs": [],
      "source": [
        "def create_dir(path):\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZNFwQ1ZiElrC"
      },
      "outputs": [],
      "source": [
        "def load_data(path, split=0.1):\n",
        "    images = shuffle(glob(os.path.join(path, \"*\", \"*.png\")))\n",
        "\n",
        "    split_size = int(len(images) * split)\n",
        "    train_x, valid_x = train_test_split(images, test_size=split_size, random_state=42)\n",
        "    train_x, test_x = train_test_split(train_x, test_size=split_size, random_state=42)\n",
        "\n",
        "    return train_x, valid_x, test_x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AIsRLI41JnsK",
        "outputId": "5b565527-9405-42c5-fb57-c9b66d9f0811"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.8/dist-packages (0.19.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.8/dist-packages (from tensorflow-addons) (2.7.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow-addons) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->tensorflow-addons) (3.0.9)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U tensorflow-addons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mDWOFrPKMG-M"
      },
      "outputs": [],
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Layer, Dense, Dropout, LayerNormalization, MultiHeadAttention, Add\n",
        "from tensorflow.keras.layers import Input, Embedding, Concatenate\n",
        "from tensorflow.keras.models import Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J2IIy6g4MIIx"
      },
      "outputs": [],
      "source": [
        "\n",
        "class ClassToken(Layer):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        w_init = tf.random_normal_initializer()\n",
        "        self.w = tf.Variable(\n",
        "            initial_value = w_init(shape=(1, 1, input_shape[-1]), dtype=tf.float32),\n",
        "            trainable = True\n",
        "        )\n",
        "\n",
        "    def call(self, inputs):\n",
        "        batch_size = tf.shape(inputs)[0]\n",
        "        hidden_dim = self.w.shape[-1]\n",
        "\n",
        "        cls = tf.broadcast_to(self.w, [batch_size, 1, hidden_dim])\n",
        "        cls = tf.cast(cls, dtype=inputs.dtype)\n",
        "        return cls\n",
        "\n",
        "def mlp(x, cf):\n",
        "    x = Dense(cf[\"mlp_dim\"], activation=\"gelu\")(x)\n",
        "    x = Dropout(cf[\"dropout_rate\"])(x)\n",
        "    x = Dense(cf[\"hidden_dim\"])(x)\n",
        "    x = Dropout(cf[\"dropout_rate\"])(x)\n",
        "    return x\n",
        "\n",
        "def transformer_encoder(x, cf):\n",
        "    skip_1 = x\n",
        "    x = LayerNormalization()(x)\n",
        "    x = MultiHeadAttention(\n",
        "        num_heads=cf[\"num_heads\"], key_dim=cf[\"hidden_dim\"]\n",
        "    )(x, x)\n",
        "    x = Add()([x, skip_1])\n",
        "\n",
        "    skip_2 = x\n",
        "    x = LayerNormalization()(x)\n",
        "    x = mlp(x, cf)\n",
        "    x = Add()([x, skip_2])\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gEtJWWJtMA8d"
      },
      "outputs": [],
      "source": [
        "\n",
        "def ViT(cf):\n",
        "    \"\"\" Inputs \"\"\"\n",
        "    input_shape = (cf[\"num_patches\"], cf[\"patch_size\"]*cf[\"patch_size\"]*cf[\"num_channels\"])\n",
        "    inputs = Input(input_shape) ## (None, 256, 3072)\n",
        "\n",
        "    \"\"\" Patch + Position Embeddings \"\"\"\n",
        "    patch_embed = Dense(cf[\"hidden_dim\"])(inputs)\n",
        "\n",
        "    positions = tf.range(start=0, limit=cf[\"num_patches\"], delta=1) ## (256,)\n",
        "    pos_embed = Embedding(input_dim=cf[\"num_patches\"], output_dim=cf[\"hidden_dim\"])(positions) ## (256, 768)\n",
        "    embed = patch_embed + pos_embed ## (None, 256, 768)\n",
        "\n",
        "    \"\"\" Adding Class Token \"\"\"\n",
        "    token = ClassToken()(embed)\n",
        "    x = Concatenate(axis=1)([token, embed]) ## (None, 257, 768)\n",
        "\n",
        "    \"\"\" Transformer Encoder \"\"\"\n",
        "    for _ in range(cf[\"num_layers\"]):\n",
        "        x = transformer_encoder(x, cf)\n",
        "\n",
        "    \"\"\" Classification Head \"\"\"\n",
        "    x = LayerNormalization()(x) ## (None, 257, 768)\n",
        "    x = x[:, 0, :] ## (None, 768)\n",
        "    x = Dropout(0.1)(x)\n",
        "    x = Dense(6, activation=\"softmax\")(x)\n",
        "\n",
        "    model = Model(inputs, x)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lkrK7ACoEl11"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, ReduceLROnPlateau, EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zx7fGvG_El3_"
      },
      "outputs": [],
      "source": [
        "def process_image_label(path):\n",
        "    \"\"\" Reading images \"\"\"\n",
        "    path = path.decode()\n",
        "    image = cv2.imread(path, cv2.IMREAD_COLOR)\n",
        "    image = cv2.resize(image, (hp[\"image_size\"], hp[\"image_size\"]))\n",
        "    image = image/255.0\n",
        "\n",
        "    \"\"\" Preprocessing to patches \"\"\"\n",
        "    patch_shape = (hp[\"patch_size\"], hp[\"patch_size\"], hp[\"num_channels\"])\n",
        "    patches = patchify(image, patch_shape, hp[\"patch_size\"])\n",
        "\n",
        "    patches = np.reshape(patches, hp[\"flat_patches_shape\"])\n",
        "    patches = patches.astype(np.float32)\n",
        "\n",
        "    \"\"\" Label \"\"\"\n",
        "    class_name = path.split(\"/\")[-2]\n",
        "    class_idx = hp[\"class_names\"].index(class_name)\n",
        "    class_idx = np.array(class_idx, dtype=np.int32)\n",
        "\n",
        "    return patches, class_idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "12vo37NFEl7o"
      },
      "outputs": [],
      "source": [
        "def parse(path):\n",
        "    patches, labels = tf.numpy_function(process_image_label, [path], [tf.float32, tf.int32])\n",
        "    labels = tf.one_hot(labels, hp[\"num_classes\"])\n",
        "\n",
        "    patches.set_shape(hp[\"flat_patches_shape\"])\n",
        "    labels.set_shape(hp[\"num_classes\"])\n",
        "\n",
        "    return patches, labels\n",
        "\n",
        "def tf_dataset(images, batch=32):\n",
        "    ds = tf.data.Dataset.from_tensor_slices((images))\n",
        "    ds = ds.map(parse).batch(batch).prefetch(8)\n",
        "    return ds\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jq3bbzKIEl-K",
        "outputId": "ea3345d5-41a0-43be-de30-4221f5c00cfa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train: 5000 - Valid: 624 - Test: 624\n",
            "Epoch 1/500\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.3976 - acc: 0.1632\n",
            "Epoch 1: val_loss improved from inf to 1.91628, saving model to files/model.h5\n",
            "157/157 [==============================] - 1598s 10s/step - loss: 2.3976 - acc: 0.1632 - val_loss: 1.9163 - val_acc: 0.1474 - lr: 1.0000e-04\n",
            "Epoch 2/500\n",
            "157/157 [==============================] - ETA: 0s - loss: 1.9383 - acc: 0.1842\n",
            "Epoch 2: val_loss improved from 1.91628 to 1.87065, saving model to files/model.h5\n",
            "157/157 [==============================] - 313s 2s/step - loss: 1.9383 - acc: 0.1842 - val_loss: 1.8707 - val_acc: 0.1859 - lr: 1.0000e-04\n",
            "Epoch 3/500\n",
            "157/157 [==============================] - ETA: 0s - loss: 1.8517 - acc: 0.2074\n",
            "Epoch 3: val_loss improved from 1.87065 to 1.76322, saving model to files/model.h5\n",
            "157/157 [==============================] - 313s 2s/step - loss: 1.8517 - acc: 0.2074 - val_loss: 1.7632 - val_acc: 0.2804 - lr: 1.0000e-04\n",
            "Epoch 4/500\n",
            "157/157 [==============================] - ETA: 0s - loss: 1.6913 - acc: 0.2792\n",
            "Epoch 4: val_loss improved from 1.76322 to 1.56279, saving model to files/model.h5\n",
            "157/157 [==============================] - 313s 2s/step - loss: 1.6913 - acc: 0.2792 - val_loss: 1.5628 - val_acc: 0.3253 - lr: 1.0000e-04\n",
            "Epoch 5/500\n",
            "157/157 [==============================] - ETA: 0s - loss: 1.5891 - acc: 0.3068\n",
            "Epoch 5: val_loss improved from 1.56279 to 1.51816, saving model to files/model.h5\n",
            "157/157 [==============================] - 313s 2s/step - loss: 1.5891 - acc: 0.3068 - val_loss: 1.5182 - val_acc: 0.3381 - lr: 1.0000e-04\n",
            "Epoch 6/500\n",
            "157/157 [==============================] - ETA: 0s - loss: 1.5187 - acc: 0.3514\n",
            "Epoch 6: val_loss improved from 1.51816 to 1.43127, saving model to files/model.h5\n",
            "157/157 [==============================] - 313s 2s/step - loss: 1.5187 - acc: 0.3514 - val_loss: 1.4313 - val_acc: 0.4071 - lr: 1.0000e-04\n",
            "Epoch 7/500\n",
            "157/157 [==============================] - ETA: 0s - loss: 1.4349 - acc: 0.3882\n",
            "Epoch 7: val_loss improved from 1.43127 to 1.35381, saving model to files/model.h5\n",
            "157/157 [==============================] - 313s 2s/step - loss: 1.4349 - acc: 0.3882 - val_loss: 1.3538 - val_acc: 0.4167 - lr: 1.0000e-04\n",
            "Epoch 8/500\n",
            "157/157 [==============================] - ETA: 0s - loss: 1.3943 - acc: 0.4030\n",
            "Epoch 8: val_loss improved from 1.35381 to 1.34192, saving model to files/model.h5\n",
            "157/157 [==============================] - 313s 2s/step - loss: 1.3943 - acc: 0.4030 - val_loss: 1.3419 - val_acc: 0.4375 - lr: 1.0000e-04\n",
            "Epoch 9/500\n",
            "157/157 [==============================] - ETA: 0s - loss: 1.3426 - acc: 0.4304\n",
            "Epoch 9: val_loss did not improve from 1.34192\n",
            "157/157 [==============================] - 293s 2s/step - loss: 1.3426 - acc: 0.4304 - val_loss: 1.3753 - val_acc: 0.4359 - lr: 1.0000e-04\n",
            "Epoch 10/500\n",
            "157/157 [==============================] - ETA: 0s - loss: 1.3311 - acc: 0.4396\n",
            "Epoch 10: val_loss improved from 1.34192 to 1.32667, saving model to files/model.h5\n",
            "157/157 [==============================] - 313s 2s/step - loss: 1.3311 - acc: 0.4396 - val_loss: 1.3267 - val_acc: 0.4744 - lr: 1.0000e-04\n",
            "Epoch 11/500\n",
            "157/157 [==============================] - ETA: 0s - loss: 1.2909 - acc: 0.4574\n",
            "Epoch 11: val_loss improved from 1.32667 to 1.29575, saving model to files/model.h5\n",
            "157/157 [==============================] - 313s 2s/step - loss: 1.2909 - acc: 0.4574 - val_loss: 1.2957 - val_acc: 0.4567 - lr: 1.0000e-04\n",
            "Epoch 12/500\n",
            "157/157 [==============================] - ETA: 0s - loss: 1.2684 - acc: 0.4688\n",
            "Epoch 12: val_loss did not improve from 1.29575\n",
            "157/157 [==============================] - 293s 2s/step - loss: 1.2684 - acc: 0.4688 - val_loss: 1.3153 - val_acc: 0.4615 - lr: 1.0000e-04\n",
            "Epoch 13/500\n",
            "157/157 [==============================] - ETA: 0s - loss: 1.5448 - acc: 0.3546\n",
            "Epoch 13: val_loss did not improve from 1.29575\n",
            "157/157 [==============================] - 292s 2s/step - loss: 1.5448 - acc: 0.3546 - val_loss: 1.7792 - val_acc: 0.3061 - lr: 1.0000e-04\n",
            "Epoch 14/500\n",
            "157/157 [==============================] - ETA: 0s - loss: 1.7811 - acc: 0.2214\n",
            "Epoch 14: val_loss did not improve from 1.29575\n",
            "157/157 [==============================] - 291s 2s/step - loss: 1.7811 - acc: 0.2214 - val_loss: 1.6961 - val_acc: 0.2788 - lr: 1.0000e-04\n",
            "Epoch 15/500\n",
            "157/157 [==============================] - ETA: 0s - loss: 1.7337 - acc: 0.2370\n",
            "Epoch 15: val_loss did not improve from 1.29575\n",
            "157/157 [==============================] - 292s 2s/step - loss: 1.7337 - acc: 0.2370 - val_loss: 1.6598 - val_acc: 0.3093 - lr: 1.0000e-04\n",
            "Epoch 16/500\n",
            "157/157 [==============================] - ETA: 0s - loss: 1.6640 - acc: 0.2852\n",
            "Epoch 16: val_loss did not improve from 1.29575\n",
            "157/157 [==============================] - 293s 2s/step - loss: 1.6640 - acc: 0.2852 - val_loss: 1.5993 - val_acc: 0.3413 - lr: 1.0000e-04\n",
            "Epoch 17/500\n",
            "157/157 [==============================] - ETA: 0s - loss: 1.6033 - acc: 0.3004\n",
            "Epoch 17: val_loss did not improve from 1.29575\n",
            "157/157 [==============================] - 292s 2s/step - loss: 1.6033 - acc: 0.3004 - val_loss: 1.5481 - val_acc: 0.3478 - lr: 1.0000e-04\n",
            "Epoch 18/500\n",
            "157/157 [==============================] - ETA: 0s - loss: 1.5508 - acc: 0.3316\n",
            "Epoch 18: val_loss did not improve from 1.29575\n",
            "157/157 [==============================] - 292s 2s/step - loss: 1.5508 - acc: 0.3316 - val_loss: 1.4995 - val_acc: 0.3462 - lr: 1.0000e-04\n",
            "Epoch 19/500\n",
            "157/157 [==============================] - ETA: 0s - loss: 1.4958 - acc: 0.3590\n",
            "Epoch 19: val_loss did not improve from 1.29575\n",
            "157/157 [==============================] - 292s 2s/step - loss: 1.4958 - acc: 0.3590 - val_loss: 1.4602 - val_acc: 0.3638 - lr: 1.0000e-04\n"
          ]
        }
      ],
      "source": [
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "\"\"\" Directory for storing files \"\"\"\n",
        "create_dir(\"files\")\n",
        "\n",
        "\"\"\" Paths \"\"\"\n",
        "dataset_path = \"/content/drive/MyDrive/SKIN_Cancer\"\n",
        "model_path = os.path.join(\"files\", \"model.h5\")\n",
        "csv_path = os.path.join(\"files\", \"log.csv\")\n",
        "\n",
        "\"\"\" Dataset \"\"\"\n",
        "train_x, valid_x, test_x = load_data(dataset_path)\n",
        "print(f\"Train: {len(train_x)} - Valid: {len(valid_x)} - Test: {len(test_x)}\")\n",
        "\n",
        "train_ds = tf_dataset(train_x, batch=hp[\"batch_size\"])\n",
        "valid_ds = tf_dataset(valid_x, batch=hp[\"batch_size\"])\n",
        "\n",
        "\"\"\" Model \"\"\"\n",
        "model = ViT(hp)\n",
        "model.compile(\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    optimizer=tf.keras.optimizers.Adam(hp[\"lr\"], clipvalue=1.0),\n",
        "    metrics=[\"acc\"]\n",
        ")\n",
        "\n",
        "callbacks = [\n",
        "    ModelCheckpoint(model_path, monitor='val_loss', verbose=1, save_best_only=True),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, min_lr=1e-10, verbose=1),\n",
        "    CSVLogger(csv_path),\n",
        "    EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=False),\n",
        "]\n",
        "\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    epochs=hp[\"num_epochs\"],\n",
        "    validation_data=valid_ds,\n",
        "    callbacks=callbacks\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e7jNbUK_EmBk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cb_9iPnnEmDF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hsl2pk62EmFd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p0YkX8HmEmHj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t846Z7nOEmJK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dxn2efxYEmLR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nZd5g8TBEmOG"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}